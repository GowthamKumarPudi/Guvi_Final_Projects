{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
      ],
      "metadata": {
        "id": "vwEI5U0xCD3D"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your actual paths or use uploaded files in Colab\n",
        "train_df = pd.read_csv(\"/content/Train_Dataset.csv\")\n",
        "test_df = pd.read_csv(\"/content/Test_Dataset.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik6e7wvFELvw",
        "outputId": "8b9fb473-45c4-40a7-ca4b-35f9199fd1f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-2997934203.py:2: DtypeWarning: Columns (1,7,8,16,17,18,19,20,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_df = pd.read_csv(\"/content/Train_Dataset.csv\")\n",
            "/tmp/ipython-input-9-2997934203.py:3: DtypeWarning: Columns (7,8,16,17,18,19,20,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  test_df = pd.read_csv(\"/content/Test_Dataset.csv\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns with more than 50% missing data\n",
        "cols_to_drop = ['Own_House_Age', 'Score_Source_1', 'Social_Circle_Default']\n",
        "train_df.drop(columns=cols_to_drop, inplace=True)\n",
        "test_df.drop(columns=cols_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "hl0N6qORET1K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = ['Client_Income', 'Credit_Amount', 'Loan_Annuity',\n",
        "                'Population_Region_Relative', 'Age_Days', 'Employed_Days',\n",
        "                'Registration_Days', 'ID_Days', 'Score_Source_3', 'Score_Source_2']\n",
        "\n",
        "for col in numeric_cols:\n",
        "    train_df[col] = pd.to_numeric(train_df[col].astype(str).str.replace(\",\", \"\").str.strip(), errors='coerce')\n",
        "    test_df[col] = pd.to_numeric(test_df[col].astype(str).str.replace(\",\", \"\").str.strip(), errors='coerce')"
      ],
      "metadata": {
        "id": "eHUQR-FJEW6j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate numerical and categorical columns\n",
        "numerical = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "numerical.remove('Default')\n",
        "categorical = train_df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Median imputation for numerical, mode for categorical\n",
        "num_imputer = SimpleImputer(strategy='median')\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "train_df[numerical] = num_imputer.fit_transform(train_df[numerical])\n",
        "test_df[numerical] = num_imputer.transform(test_df[numerical])\n",
        "\n",
        "train_df[categorical] = cat_imputer.fit_transform(train_df[categorical])\n",
        "test_df[categorical] = cat_imputer.transform(test_df[categorical])"
      ],
      "metadata": {
        "id": "a9ZuHnFAEaXm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoders = {}\n",
        "for col in categorical:\n",
        "    le = LabelEncoder()\n",
        "    combined = pd.concat([train_df[col], test_df[col]], axis=0).astype(str)\n",
        "    le.fit(combined)\n",
        "    train_df[col] = le.transform(train_df[col].astype(str))\n",
        "    test_df[col] = le.transform(test_df[col].astype(str))\n",
        "    encoders[col] = le"
      ],
      "metadata": {
        "id": "piDn0OZaEeQ8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df.drop(\"Default\", axis=1)\n",
        "y = train_df[\"Default\"]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "NL7gQ8fcEhUb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(test_df)"
      ],
      "metadata": {
        "id": "fIXdH8EUEkAr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42)\n",
        "rf.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "u3MTm_zUEmT3",
        "outputId": "21fa4ed5-58a7-405a-f6aa-ee125ca43ee0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', max_depth=10, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=10, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = rf.predict(X_val_scaled)\n",
        "y_val_proba = rf.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_val_pred))\n",
        "print(\"\\nROC AUC Score:\", roc_auc_score(y_val, y_val_proba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qnm2kZnEojB",
        "outputId": "72bfeabc-ef73-404b-aea8-a11dc05ce7d3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[17795  4608]\n",
            " [  947  1022]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.79      0.86     22403\n",
            "           1       0.18      0.52      0.27      1969\n",
            "\n",
            "    accuracy                           0.77     24372\n",
            "   macro avg       0.57      0.66      0.57     24372\n",
            "weighted avg       0.89      0.77      0.82     24372\n",
            "\n",
            "\n",
            "ROC AUC Score: 0.7336492720595558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "test_preds = rf.predict(X_test_scaled)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    \"UniqueID\": test_df[\"UniqueID\"],  # make sure this column exists\n",
        "    \"Default\": test_preds\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "submission.to_csv(\"vehicle_loan_default_predictions.csv\", index=False)\n",
        "print(\"✅ Submission saved as 'vehicle_loan_default_predictions.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "nfGR8hNuEwmK",
        "outputId": "b537c1d7-66c5-433c-819d-50fdea7d5451"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'UniqueID'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'UniqueID'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-18-377433771.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create submission file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m submission = pd.DataFrame({\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m\"UniqueID\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"UniqueID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# make sure this column exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"Default\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m })\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'UniqueID'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for identifier column\n",
        "possible_id_columns = [col for col in test_df.columns if 'id' in col.lower()]\n",
        "print(\"Possible ID columns in test data:\", possible_id_columns)\n",
        "\n",
        "# Use the first ID-like column if found\n",
        "if possible_id_columns:\n",
        "    id_column = possible_id_columns[0]\n",
        "else:\n",
        "    id_column = None\n",
        "    print(\"⚠️ No ID column found. Using index instead.\")\n",
        "\n",
        "# Prepare submission\n",
        "submission = pd.DataFrame({\n",
        "    id_column if id_column else \"Index\": test_df[id_column] if id_column else test_df.index,\n",
        "    \"Default\": test_preds\n",
        "})\n",
        "\n",
        "# Rename column to 'UniqueID' if needed\n",
        "if id_column and id_column.lower() != \"uniqueid\":\n",
        "    submission.rename(columns={id_column: \"UniqueID\"}, inplace=True)\n",
        "\n",
        "# Save\n",
        "submission.to_csv(\"vehicle_loan_default_predictions.csv\", index=False)\n",
        "print(\"✅ Submission saved as 'vehicle_loan_default_predictions.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gWtTZ4hFCDL",
        "outputId": "22a48fa3-7fa8-4c3e-dced-04d6a1590375"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Possible ID columns in test data: ['ID', 'ID_Days']\n",
            "✅ Submission saved as 'vehicle_loan_default_predictions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0gkaes0RF2tr",
        "outputId": "ef635ccb-9695-4d49-bd3d-8a245852aa4a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.47.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.47.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.47.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.47.0 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import io\n",
        "\n",
        "st.set_page_config(page_title=\"NBFC Loan Default Predictor\", layout=\"wide\")\n",
        "st.title(\"🚗 NBFC Vehicle Loan Default Prediction App\")\n",
        "\n",
        "# Step 1: Upload files\n",
        "train_file = st.file_uploader(\"Upload Train_Dataset.csv\", type=\"csv\")\n",
        "test_file = st.file_uploader(\"Upload Test_Dataset.csv\", type=\"csv\")\n",
        "\n",
        "if train_file and test_file:\n",
        "    train_df = pd.read_csv(train_file)\n",
        "    test_df = pd.read_csv(test_file)\n",
        "    st.success(\"✅ Files uploaded successfully!\")\n",
        "\n",
        "    if st.button(\"🚀 Train Model and Predict\"):\n",
        "\n",
        "        # Drop high-missing columns\n",
        "        drop_cols = ['Own_House_Age', 'Score_Source_1', 'Social_Circle_Default']\n",
        "        for col in drop_cols:\n",
        "            if col in train_df.columns: train_df.drop(columns=col, inplace=True)\n",
        "            if col in test_df.columns: test_df.drop(columns=col, inplace=True)\n",
        "\n",
        "        # Convert numeric-looking object columns\n",
        "        numeric_cols = ['Client_Income', 'Credit_Amount', 'Loan_Annuity',\n",
        "                        'Population_Region_Relative', 'Age_Days', 'Employed_Days',\n",
        "                        'Registration_Days', 'ID_Days', 'Score_Source_3', 'Score_Source_2']\n",
        "\n",
        "        for col in numeric_cols:\n",
        "            train_df[col] = pd.to_numeric(train_df[col].astype(str).str.replace(\",\", \"\"), errors='coerce')\n",
        "            test_df[col] = pd.to_numeric(test_df[col].astype(str).str.replace(\",\", \"\"), errors='coerce')\n",
        "\n",
        "        # Impute missing values\n",
        "        numerical = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "        if 'Default' in numerical: numerical.remove('Default')\n",
        "        categorical = train_df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "        num_imputer = SimpleImputer(strategy='median')\n",
        "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "        train_df[numerical] = num_imputer.fit_transform(train_df[numerical])\n",
        "        test_df[numerical] = num_imputer.transform(test_df[numerical])\n",
        "\n",
        "        train_df[categorical] = cat_imputer.fit_transform(train_df[categorical])\n",
        "        test_df[categorical] = cat_imputer.transform(test_df[categorical])\n",
        "\n",
        "        # Encode categoricals\n",
        "        encoders = {}\n",
        "        for col in categorical:\n",
        "            le = LabelEncoder()\n",
        "            combined = pd.concat([train_df[col], test_df[col]], axis=0).astype(str)\n",
        "            le.fit(combined)\n",
        "            train_df[col] = le.transform(train_df[col].astype(str))\n",
        "            test_df[col] = le.transform(test_df[col].astype(str))\n",
        "            encoders[col] = le\n",
        "\n",
        "        # Split features and labels\n",
        "        X = train_df.drop(\"Default\", axis=1)\n",
        "        y = train_df[\"Default\"]\n",
        "\n",
        "        # Train-test split\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "        # Scaling\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_val_scaled = scaler.transform(X_val)\n",
        "        X_test_scaled = scaler.transform(test_df)\n",
        "\n",
        "        # Train Random Forest\n",
        "        model = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42)\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        y_pred = model.predict(X_val_scaled)\n",
        "        y_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "        st.subheader(\"📊 Evaluation on Validation Set\")\n",
        "        st.text(\"Confusion Matrix:\")\n",
        "        st.text(confusion_matrix(y_val, y_pred))\n",
        "        st.text(\"\\nClassification Report:\")\n",
        "        st.text(classification_report(y_val, y_pred))\n",
        "        st.text(f\"ROC AUC Score: {roc_auc_score(y_val, y_proba):.4f}\")\n",
        "\n",
        "        # Predict on test\n",
        "        test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "        # Find ID column for submission\n",
        "        possible_ids = [col for col in test_df.columns if 'id' in col.lower()]\n",
        "        id_col = possible_ids[0] if possible_ids else None\n",
        "\n",
        "        submission = pd.DataFrame({\n",
        "            \"UniqueID\": test_df[id_col] if id_col else test_df.index,\n",
        "            \"Default\": test_preds\n",
        "        })\n",
        "\n",
        "        csv_buffer = io.StringIO()\n",
        "        submission.to_csv(csv_buffer, index=False)\n",
        "        st.download_button(\"📥 Download Predictions\", data=csv_buffer.getvalue(), file_name=\"vehicle_loan_default_predictions.csv\", mime='text/csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57HFIdQNF0AH",
        "outputId": "1e6c152d-fa0c-4c24-a783-2f38201686a7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-21 13:06:32.272 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.277 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.450 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-07-21 13:06:32.451 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.452 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.453 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.460 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.461 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.463 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.463 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.464 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.465 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.466 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.467 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.468 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:06:32.470 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import io\n",
        "\n",
        "st.set_page_config(page_title=\"NBFC Loan Default Predictor\", layout=\"wide\")\n",
        "st.title(\"NBFC Vehicle Loan Default Prediction App\")\n",
        "\n",
        "# Step 1: Upload files\n",
        "train_file = st.file_uploader(\"Upload Train_Dataset.csv\", type=\"csv\")\n",
        "test_file = st.file_uploader(\"Upload Test_Dataset.csv\", type=\"csv\")\n",
        "\n",
        "if train_file and test_file:\n",
        "    train_df = pd.read_csv(train_file)\n",
        "    test_df = pd.read_csv(test_file)\n",
        "    st.success(\"✅Files uploaded successfully!\")\n",
        "\n",
        "    if st.button(\"🚀Train Model and Predict\"):\n",
        "\n",
        "        # Drop high-missing columns\n",
        "        drop_cols = ['Own_House_Age', 'Score_Source_1', 'Social_Circle_Default']\n",
        "        for col in drop_cols:\n",
        "            if col in train_df.columns: train_df.drop(columns=col, inplace=True)\n",
        "            if col in test_df.columns: test_df.drop(columns=col, inplace=True)\n",
        "\n",
        "        # Convert numeric-looking object columns\n",
        "        numeric_cols = ['Client_Income', 'Credit_Amount', 'Loan_Annuity',\n",
        "                        'Population_Region_Relative', 'Age_Days', 'Employed_Days',\n",
        "                        'Registration_Days', 'ID_Days', 'Score_Source_3', 'Score_Source_2']\n",
        "\n",
        "        for col in numeric_cols:\n",
        "            train_df[col] = pd.to_numeric(train_df[col].astype(str).str.replace(\",\", \"\"), errors='coerce')\n",
        "            test_df[col] = pd.to_numeric(test_df[col].astype(str).str.replace(\",\", \"\"), errors='coerce')\n",
        "\n",
        "        # Impute missing values\n",
        "        numerical = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "        if 'Default' in numerical: numerical.remove('Default')\n",
        "        categorical = train_df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "        num_imputer = SimpleImputer(strategy='median')\n",
        "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "        train_df[numerical] = num_imputer.fit_transform(train_df[numerical])\n",
        "        test_df[numerical] = num_imputer.transform(test_df[numerical])\n",
        "\n",
        "        train_df[categorical] = cat_imputer.fit_transform(train_df[categorical])\n",
        "        test_df[categorical] = cat_imputer.transform(test_df[categorical])\n",
        "\n",
        "        # Encode categoricals\n",
        "        encoders = {}\n",
        "        for col in categorical:\n",
        "            le = LabelEncoder()\n",
        "            combined = pd.concat([train_df[col], test_df[col]], axis=0).astype(str)\n",
        "            le.fit(combined)\n",
        "            train_df[col] = le.transform(train_df[col].astype(str))\n",
        "            test_df[col] = le.transform(test_df[col].astype(str))\n",
        "            encoders[col] = le\n",
        "\n",
        "        # Split features and labels\n",
        "        X = train_df.drop(\"Default\", axis=1)\n",
        "        y = train_df[\"Default\"]\n",
        "\n",
        "        # Train-test split\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "        # Scaling\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_val_scaled = scaler.transform(X_val)\n",
        "        X_test_scaled = scaler.transform(test_df)\n",
        "\n",
        "        # Train Random Forest\n",
        "        model = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42)\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        y_pred = model.predict(X_val_scaled)\n",
        "        y_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "        st.subheader(\"📊Evaluation on Validation Set\")\n",
        "        st.text(\"Confusion Matrix:\")\n",
        "        st.text(confusion_matrix(y_val, y_pred))\n",
        "        st.text(\"\\nClassification Report:\")\n",
        "        st.text(classification_report(y_val, y_pred))\n",
        "        st.text(f\"ROC AUC Score: {roc_auc_score(y_val, y_proba):.4f}\")\n",
        "\n",
        "        # Predict on test\n",
        "        test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "        # Find ID column for submission\n",
        "        possible_ids = [col for col in test_df.columns if 'id' in col.lower()]\n",
        "        id_col = possible_ids[0] if possible_ids else None\n",
        "\n",
        "        submission = pd.DataFrame({\n",
        "            \"UniqueID\": test_df[id_col] if id_col else test_df.index,\n",
        "            \"Default\": test_preds\n",
        "        })\n",
        "\n",
        "        csv_buffer = io.StringIO()\n",
        "        submission.to_csv(csv_buffer, index=False)\n",
        "        st.download_button(\"📥Download Predictions\", data=csv_buffer.getvalue(), file_name=\"vehicle_loan_default_predictions.csv\", mime='text/csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLAHeZkRF-vA",
        "outputId": "3964c48f-208f-4356-e460-cb6f4471b478"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting my_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvZdvBXYGP5G",
        "outputId": "6a461cff-111b-4ecc-fac9-b84ba60fded6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.143.172.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qQNBD8uhGVkC",
        "outputId": "37947aaa-e382-46af-a6ef-f082d8471aa8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m debug@4.1.1: Debug versions >=3.2.0 <3.2.7 || >=4 <4.3.1 have a low-severity ReDos regression when used in a Node.js environment. It is recommended you upgrade to 3.2.7 or 4.3.1. (https://github.com/visionmedia/debug/issues/797)\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m axios@0.19.0: Critical security vulnerability fixed in v0.21.1. For more information, see https://github.com/axios/axios/pull/3410\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "added 38 packages, removed 74 packages, changed 5 packages, and audited 60 packages in 6s\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K5 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "\u001b[31m\u001b[1m6\u001b[22m\u001b[39m vulnerabilities (1 \u001b[1mlow\u001b[22m, 2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m, 3 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m)\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm audit fix --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yxCBZznqGafJ",
        "outputId": "d9f8b330-11f2-4f04-c504-520ac3205752"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94musing --force\u001b[39m Recommended protections disabled.\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94maudit\u001b[39m Updating localtunnel to 2.0.2, which is a SemVer major change.\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "added 5 packages, removed 42 packages, changed 15 packages, and audited 23 packages in 2s\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "\u001b[1m# npm audit report\u001b[22m\n",
            "\n",
            "\u001b[1maxios\u001b[22m  <=0.29.0\n",
            "Severity: \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m\n",
            "\u001b[1mAxios Cross-Site Request Forgery Vulnerability\u001b[22m - https://github.com/advisories/GHSA-wf5p-g6vw-rhxx\n",
            "\u001b[1maxios Requests Vulnerable To Possible SSRF and Credential Leakage via Absolute URL\u001b[22m - https://github.com/advisories/GHSA-jr5f-v2jv-69x6\n",
            "\u001b[33m\u001b[1mfix available\u001b[22m\u001b[39m via `npm audit fix --force`\n",
            "Will install localtunnel@1.8.3, which is a breaking change\n",
            "\u001b[2mnode_modules/axios\u001b[22m\n",
            "  \u001b[1mlocaltunnel\u001b[22m  >=1.9.0\n",
            "  Depends on vulnerable versions of \u001b[1maxios\u001b[22m\n",
            "  \u001b[2mnode_modules/localtunnel\u001b[22m\n",
            "\n",
            "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run my_app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1v-1AP8Gej-",
        "outputId": "393c9c68-da7b-46c0-f955-7cb0dca1b891"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.143.172.9:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://lemon-hats-visit.loca.lt\n",
            "/content/my_app.py:19: DtypeWarning: Columns (1,7,8,16,17,18,19,20,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_df = pd.read_csv(train_file)\n",
            "/content/my_app.py:20: DtypeWarning: Columns (7,8,16,17,18,19,20,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  test_df = pd.read_csv(test_file)\n",
            "/content/my_app.py:19: DtypeWarning: Columns (1,7,8,16,17,18,19,20,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_df = pd.read_csv(train_file)\n",
            "/content/my_app.py:20: DtypeWarning: Columns (7,8,16,17,18,19,20,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  test_df = pd.read_csv(test_file)\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import io\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Streamlit config\n",
        "st.set_page_config(page_title=\"NBFC Loan Default Predictor\", layout=\"wide\")\n",
        "st.title(\"🚗 NBFC Vehicle Loan Default Prediction App\")\n",
        "\n",
        "# File upload section\n",
        "train_file = st.file_uploader(\"📤 Upload Train_Dataset.csv\", type=\"csv\")\n",
        "test_file = st.file_uploader(\"📤 Upload Test_Dataset.csv\", type=\"csv\")\n",
        "\n",
        "# Run pipeline if files uploaded\n",
        "if train_file and test_file:\n",
        "    train_df = pd.read_csv(train_file)\n",
        "    test_df = pd.read_csv(test_file)\n",
        "    st.success(\"✅ Files uploaded successfully!\")\n",
        "\n",
        "    if st.button(\"🚀 Train Model and Predict\"):\n",
        "\n",
        "        # Drop high-missing columns\n",
        "        drop_cols = ['Own_House_Age', 'Score_Source_1', 'Social_Circle_Default']\n",
        "        for col in drop_cols:\n",
        "            if col in train_df.columns: train_df.drop(columns=col, inplace=True)\n",
        "            if col in test_df.columns: test_df.drop(columns=col, inplace=True)\n",
        "\n",
        "        # Convert numeric-like columns\n",
        "        numeric_cols = ['Client_Income', 'Credit_Amount', 'Loan_Annuity',\n",
        "                        'Population_Region_Relative', 'Age_Days', 'Employed_Days',\n",
        "                        'Registration_Days', 'ID_Days', 'Score_Source_3', 'Score_Source_2']\n",
        "        for col in numeric_cols:\n",
        "            train_df[col] = pd.to_numeric(train_df[col].astype(str).str.replace(\",\", \"\"), errors='coerce')\n",
        "            test_df[col] = pd.to_numeric(test_df[col].astype(str).str.replace(\",\", \"\"), errors='coerce')\n",
        "\n",
        "        # Handle missing values\n",
        "        numerical = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "        if 'Default' in numerical: numerical.remove('Default')\n",
        "        categorical = train_df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "        num_imputer = SimpleImputer(strategy='median')\n",
        "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "        train_df[numerical] = num_imputer.fit_transform(train_df[numerical])\n",
        "        test_df[numerical] = num_imputer.transform(test_df[numerical])\n",
        "        train_df[categorical] = cat_imputer.fit_transform(train_df[categorical])\n",
        "        test_df[categorical] = cat_imputer.transform(test_df[categorical])\n",
        "\n",
        "        # Encode categorical features\n",
        "        encoders = {}\n",
        "        for col in categorical:\n",
        "            le = LabelEncoder()\n",
        "            all_vals = pd.concat([train_df[col], test_df[col]], axis=0).astype(str)\n",
        "            le.fit(all_vals)\n",
        "            train_df[col] = le.transform(train_df[col].astype(str))\n",
        "            test_df[col] = le.transform(test_df[col].astype(str))\n",
        "            encoders[col] = le\n",
        "\n",
        "        # Split train data\n",
        "        X = train_df.drop(\"Default\", axis=1)\n",
        "        y = train_df[\"Default\"]\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "        # Scale\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_val_scaled = scaler.transform(X_val)\n",
        "        X_test_scaled = scaler.transform(test_df)\n",
        "\n",
        "        # Train Random Forest\n",
        "        model = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42)\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Evaluation\n",
        "        y_pred = model.predict(X_val_scaled)\n",
        "        y_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
        "        cm = confusion_matrix(y_val, y_pred)\n",
        "        report = classification_report(y_val, y_pred, output_dict=True)\n",
        "        roc_auc = roc_auc_score(y_val, y_proba)\n",
        "\n",
        "        # 📊 Confusion Matrix\n",
        "        st.subheader(\"📊 Model Evaluation on Validation Set\")\n",
        "        fig, ax = plt.subplots()\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Default\", \"Default\"], yticklabels=[\"No Default\", \"Default\"], ax=ax)\n",
        "        ax.set_xlabel(\"Predicted\")\n",
        "        ax.set_ylabel(\"Actual\")\n",
        "        ax.set_title(\"Confusion Matrix\")\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # 📈 Classification Report\n",
        "        st.markdown(\"### 🔍 Classification Report Summary\")\n",
        "        metrics_df = pd.DataFrame(report).transpose()\n",
        "        st.dataframe(metrics_df.style.format({\n",
        "            \"precision\": \"{:.2f}\",\n",
        "            \"recall\": \"{:.2f}\",\n",
        "            \"f1-score\": \"{:.2f}\",\n",
        "            \"support\": \"{:.0f}\"\n",
        "        }).highlight_max(axis=0, color='lightgreen'))\n",
        "\n",
        "        # ROC AUC\n",
        "        st.markdown(f\"### 🧮 ROC AUC Score: **{roc_auc:.4f}**\")\n",
        "\n",
        "        # 📘 Interpretation\n",
        "        st.markdown(\"\"\"\n",
        "#### 📘 Quick Interpretation:\n",
        "- **Precision**: Out of predicted defaults, how many were correct? (Low means many false positives)\n",
        "- **Recall**: Out of actual defaults, how many did we catch? (Important in risk modeling)\n",
        "- **F1-score**: Balances precision and recall.\n",
        "- **ROC AUC**: Area under the curve — 0.73 means decent discrimination between defaulters vs. non-defaulters.\n",
        "\"\"\")\n",
        "\n",
        "        # Prediction\n",
        "        test_preds = model.predict(X_test_scaled)\n",
        "        possible_ids = [col for col in test_df.columns if 'id' in col.lower()]\n",
        "        id_col = possible_ids[0] if possible_ids else None\n",
        "\n",
        "        submission = pd.DataFrame({\n",
        "            \"UniqueID\": test_df[id_col] if id_col else test_df.index,\n",
        "            \"Default\": test_preds\n",
        "        })\n",
        "\n",
        "        csv_buffer = io.StringIO()\n",
        "        submission.to_csv(csv_buffer, index=False)\n",
        "        st.download_button(\"📥 Download Prediction CSV\", data=csv_buffer.getvalue(), file_name=\"vehicle_loan_default_predictions.csv\", mime='text/csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ts1nRHPIsIK",
        "outputId": "ef7d5842-fd4c-4be9-e960-e031852d74b4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-21 13:18:37.802 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.812 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.814 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.815 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.816 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.817 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.818 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.819 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.820 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.822 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.822 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.823 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.824 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.825 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-21 13:18:37.826 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import io\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Streamlit config\n",
        "st.set_page_config(page_title=\"NBFC Loan Default Predictor\", layout=\"wide\")\n",
        "st.title(\"NBFC Vehicle Loan Default Prediction App\")\n",
        "\n",
        "# File upload section\n",
        "train_file = st.file_uploader(\"📤Upload Train_Dataset.csv\", type=\"csv\")\n",
        "test_file = st.file_uploader(\"📤Upload Test_Dataset.csv\", type=\"csv\")\n",
        "\n",
        "# Run pipeline if files uploaded\n",
        "if train_file and test_file:\n",
        "    train_df = pd.read_csv(train_file)\n",
        "    test_df = pd.read_csv(test_file)\n",
        "    st.success(\"✅Files uploaded successfully!\")\n",
        "\n",
        "    if st.button(\"🚀Train Model and Predict\"):\n",
        "\n",
        "        # Drop high-missing columns\n",
        "        drop_cols = ['Own_House_Age', 'Score_Source_1', 'Social_Circle_Default']\n",
        "        for col in drop_cols:\n",
        "            if col in train_df.columns: train_df.drop(columns=col, inplace=True)\n",
        "            if col in test_df.columns: test_df.drop(columns=col, inplace=True)\n",
        "\n",
        "        # Convert numeric-like columns\n",
        "        numeric_cols = ['Client_Income', 'Credit_Amount', 'Loan_Annuity',\n",
        "                        'Population_Region_Relative', 'Age_Days', 'Employed_Days',\n",
        "                        'Registration_Days', 'ID_Days', 'Score_Source_3', 'Score_Source_2']\n",
        "        for col in numeric_cols:\n",
        "            train_df[col] = pd.to_numeric(train_df[col].astype(str).str.replace(\",\", \"\"), errors='coerce')\n",
        "            test_df[col] = pd.to_numeric(test_df[col].astype(str).str.replace(\",\", \"\"), errors='coerce')\n",
        "\n",
        "        # Handle missing values\n",
        "        numerical = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "        if 'Default' in numerical: numerical.remove('Default')\n",
        "        categorical = train_df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "        num_imputer = SimpleImputer(strategy='median')\n",
        "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "        train_df[numerical] = num_imputer.fit_transform(train_df[numerical])\n",
        "        test_df[numerical] = num_imputer.transform(test_df[numerical])\n",
        "        train_df[categorical] = cat_imputer.fit_transform(train_df[categorical])\n",
        "        test_df[categorical] = cat_imputer.transform(test_df[categorical])\n",
        "\n",
        "        # Encode categorical features\n",
        "        encoders = {}\n",
        "        for col in categorical:\n",
        "            le = LabelEncoder()\n",
        "            all_vals = pd.concat([train_df[col], test_df[col]], axis=0).astype(str)\n",
        "            le.fit(all_vals)\n",
        "            train_df[col] = le.transform(train_df[col].astype(str))\n",
        "            test_df[col] = le.transform(test_df[col].astype(str))\n",
        "            encoders[col] = le\n",
        "\n",
        "        # Split train data\n",
        "        X = train_df.drop(\"Default\", axis=1)\n",
        "        y = train_df[\"Default\"]\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "        # Scale\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_val_scaled = scaler.transform(X_val)\n",
        "        X_test_scaled = scaler.transform(test_df)\n",
        "\n",
        "        # Train Random Forest\n",
        "        model = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42)\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Evaluation\n",
        "        y_pred = model.predict(X_val_scaled)\n",
        "        y_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
        "        cm = confusion_matrix(y_val, y_pred)\n",
        "        report = classification_report(y_val, y_pred, output_dict=True)\n",
        "        roc_auc = roc_auc_score(y_val, y_proba)\n",
        "\n",
        "        # 📊Confusion Matrix\n",
        "        st.subheader(\"📊Model Evaluation on Validation Set\")\n",
        "        fig, ax = plt.subplots()\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Default\", \"Default\"], yticklabels=[\"No Default\", \"Default\"], ax=ax)\n",
        "        ax.set_xlabel(\"Predicted\")\n",
        "        ax.set_ylabel(\"Actual\")\n",
        "        ax.set_title(\"Confusion Matrix\")\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # 📈Classification Report\n",
        "        st.markdown(\"### Classification Report Summary\")\n",
        "        metrics_df = pd.DataFrame(report).transpose()\n",
        "        st.dataframe(metrics_df.style.format({\n",
        "            \"precision\": \"{:.2f}\",\n",
        "            \"recall\": \"{:.2f}\",\n",
        "            \"f1-score\": \"{:.2f}\",\n",
        "            \"support\": \"{:.0f}\"\n",
        "        }).highlight_max(axis=0, color='lightgreen'))\n",
        "\n",
        "        # ROC AUC\n",
        "        st.markdown(f\"### 🧮 ROC AUC Score: **{roc_auc:.4f}**\")\n",
        "\n",
        "        # 📘Interpretation\n",
        "        st.markdown(\"\"\"\n",
        "#### 📘Quick Interpretation:\n",
        "- **Precision**: Out of predicted defaults, how many were correct? (Low means many false positives)\n",
        "- **Recall**: Out of actual defaults, how many did we catch? (Important in risk modeling)\n",
        "- **F1-score**: Balances precision and recall.\n",
        "- **ROC AUC**: Area under the curve — 0.73 means decent discrimination between defaulters vs. non-defaulters.\n",
        "\"\"\")\n",
        "\n",
        "        # Prediction\n",
        "        test_preds = model.predict(X_test_scaled)\n",
        "        possible_ids = [col for col in test_df.columns if 'id' in col.lower()]\n",
        "        id_col = possible_ids[0] if possible_ids else None\n",
        "\n",
        "        submission = pd.DataFrame({\n",
        "            \"UniqueID\": test_df[id_col] if id_col else test_df.index,\n",
        "            \"Default\": test_preds\n",
        "        })\n",
        "\n",
        "        csv_buffer = io.StringIO()\n",
        "        submission.to_csv(csv_buffer, index=False)\n",
        "        st.download_button(\"📥Download Prediction CSV\", data=csv_buffer.getvalue(), file_name=\"vehicle_loan_default_predictions.csv\", mime='text/csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxpHtkRQIvlg",
        "outputId": "74796670-478a-4fcf-9511-830b4edaea88"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting my_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xawoJj4I3-t",
        "outputId": "bf341756-5968-49e3-f513-db66385c559d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.143.172.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZwxun5_I5l2",
        "outputId": "8927b529-3daa-4753-d64f-46116d8aa272"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m debug@4.1.1: Debug versions >=3.2.0 <3.2.7 || >=4 <4.3.1 have a low-severity ReDos regression when used in a Node.js environment. It is recommended you upgrade to 3.2.7 or 4.3.1. (https://github.com/visionmedia/debug/issues/797)\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m axios@0.19.0: Critical security vulnerability fixed in v0.21.1. For more information, see https://github.com/axios/axios/pull/3410\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "added 38 packages, removed 74 packages, changed 5 packages, and audited 60 packages in 3s\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K5 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "\u001b[31m\u001b[1m6\u001b[22m\u001b[39m vulnerabilities (1 \u001b[1mlow\u001b[22m, 2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m, 3 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m)\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm audit fix --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6iLZhvEJI7z7",
        "outputId": "a2b1dcb0-e0c9-412e-f7e9-aed5fc52885b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94musing --force\u001b[39m Recommended protections disabled.\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94maudit\u001b[39m Updating localtunnel to 2.0.2, which is a SemVer major change.\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "added 5 packages, removed 42 packages, changed 15 packages, and audited 23 packages in 2s\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "\u001b[1m# npm audit report\u001b[22m\n",
            "\n",
            "\u001b[1maxios\u001b[22m  <=0.29.0\n",
            "Severity: \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m\n",
            "\u001b[1mAxios Cross-Site Request Forgery Vulnerability\u001b[22m - https://github.com/advisories/GHSA-wf5p-g6vw-rhxx\n",
            "\u001b[1maxios Requests Vulnerable To Possible SSRF and Credential Leakage via Absolute URL\u001b[22m - https://github.com/advisories/GHSA-jr5f-v2jv-69x6\n",
            "\u001b[33m\u001b[1mfix available\u001b[22m\u001b[39m via `npm audit fix --force`\n",
            "Will install localtunnel@1.8.3, which is a breaking change\n",
            "\u001b[2mnode_modules/axios\u001b[22m\n",
            "  \u001b[1mlocaltunnel\u001b[22m  >=1.9.0\n",
            "  Depends on vulnerable versions of \u001b[1maxios\u001b[22m\n",
            "  \u001b[2mnode_modules/localtunnel\u001b[22m\n",
            "\n",
            "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run my_app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYf1aeOdJCnX",
        "outputId": "e0099865-c0ae-406c-d293-e11b8f515ce1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.143.172.9:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://chubby-cats-fix.loca.lt\n",
            "/content/my_app.py:25: DtypeWarning: Columns (1,7,8,16,17,18,19,20,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_df = pd.read_csv(train_file)\n",
            "/content/my_app.py:26: DtypeWarning: Columns (7,8,16,17,18,19,20,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  test_df = pd.read_csv(test_file)\n",
            "/content/my_app.py:25: DtypeWarning: Columns (1,7,8,16,17,18,19,20,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_df = pd.read_csv(train_file)\n",
            "/content/my_app.py:26: DtypeWarning: Columns (7,8,16,17,18,19,20,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  test_df = pd.read_csv(test_file)\n",
            "/content/my_app.py:25: DtypeWarning: Columns (1,7,8,16,17,18,19,20,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_df = pd.read_csv(train_file)\n",
            "/content/my_app.py:26: DtypeWarning: Columns (7,8,16,17,18,19,20,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  test_df = pd.read_csv(test_file)\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}